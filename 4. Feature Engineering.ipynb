{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading in the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/edmonton_cleaned.parquet', engine='auto')\n",
    "df = df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 22)"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenization & Data Splits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "              business_id                            name  \\\n1  WKMJwqnfZKsAae75RMP6jA  Roast Coffeehouse and Wine Bar   \n2  WKMJwqnfZKsAae75RMP6jA  Roast Coffeehouse and Wine Bar   \n4  WKMJwqnfZKsAae75RMP6jA  Roast Coffeehouse and Wine Bar   \n\n               address      city state postal_code   latitude   longitude  \\\n1  10359 104 Street NW  Edmonton    AB     T5J 1B9  53.546045 -113.499169   \n2  10359 104 Street NW  Edmonton    AB     T5J 1B9  53.546045 -113.499169   \n4  10359 104 Street NW  Edmonton    AB     T5J 1B9  53.546045 -113.499169   \n\n   stars_x  review_count  ...  \\\n1      4.0            40  ...   \n2      4.0            40  ...   \n4      4.0            40  ...   \n\n                                          categories  \\\n1  Coffee & Tea, Food, Cafes, Bars, Wine Bars, Re...   \n2  Coffee & Tea, Food, Cafes, Bars, Wine Bars, Re...   \n4  Coffee & Tea, Food, Cafes, Bars, Wine Bars, Re...   \n\n                                               hours               review_id  \\\n1  b'{\"Monday\": \"8:0-18:0\", \"Tuesday\": \"8:0-18:0\"...  bAy8ROEYO_3aTBhW5LoR4g   \n2  b'{\"Monday\": \"8:0-18:0\", \"Tuesday\": \"8:0-18:0\"...  zPDHE7TrXs7EJT06qD8yTA   \n4  b'{\"Monday\": \"8:0-18:0\", \"Tuesday\": \"8:0-18:0\"...  pLnTjS90gUlsq2tAjI9prA   \n\n                  user_id stars_y useful  funny  cool  \\\n1  7qFH1RkPivVRcwxLwhyixg       4      2      0     1   \n2  FLeyjgc05C2V6QI9nVQ48Q       4      0      0     0   \n4  G3h8pIclwUbuu3itJqF7ug       4      7      0     4   \n\n                                                text                date  \n1  I'm not a coffee connoisseur so I'm not review... 2013-05-28 23:16:30  \n2  I really loved it here, makes me wish I lived ... 2013-09-04 19:49:33  \n4  With a Toast to Roast, I say welcome to the E-... 2012-09-11 23:54:24  \n\n[3 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>city</th>\n      <th>state</th>\n      <th>postal_code</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>stars_x</th>\n      <th>review_count</th>\n      <th>...</th>\n      <th>categories</th>\n      <th>hours</th>\n      <th>review_id</th>\n      <th>user_id</th>\n      <th>stars_y</th>\n      <th>useful</th>\n      <th>funny</th>\n      <th>cool</th>\n      <th>text</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>WKMJwqnfZKsAae75RMP6jA</td>\n      <td>Roast Coffeehouse and Wine Bar</td>\n      <td>10359 104 Street NW</td>\n      <td>Edmonton</td>\n      <td>AB</td>\n      <td>T5J 1B9</td>\n      <td>53.546045</td>\n      <td>-113.499169</td>\n      <td>4.0</td>\n      <td>40</td>\n      <td>...</td>\n      <td>Coffee &amp; Tea, Food, Cafes, Bars, Wine Bars, Re...</td>\n      <td>b'{\"Monday\": \"8:0-18:0\", \"Tuesday\": \"8:0-18:0\"...</td>\n      <td>bAy8ROEYO_3aTBhW5LoR4g</td>\n      <td>7qFH1RkPivVRcwxLwhyixg</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>I'm not a coffee connoisseur so I'm not review...</td>\n      <td>2013-05-28 23:16:30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WKMJwqnfZKsAae75RMP6jA</td>\n      <td>Roast Coffeehouse and Wine Bar</td>\n      <td>10359 104 Street NW</td>\n      <td>Edmonton</td>\n      <td>AB</td>\n      <td>T5J 1B9</td>\n      <td>53.546045</td>\n      <td>-113.499169</td>\n      <td>4.0</td>\n      <td>40</td>\n      <td>...</td>\n      <td>Coffee &amp; Tea, Food, Cafes, Bars, Wine Bars, Re...</td>\n      <td>b'{\"Monday\": \"8:0-18:0\", \"Tuesday\": \"8:0-18:0\"...</td>\n      <td>zPDHE7TrXs7EJT06qD8yTA</td>\n      <td>FLeyjgc05C2V6QI9nVQ48Q</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>I really loved it here, makes me wish I lived ...</td>\n      <td>2013-09-04 19:49:33</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WKMJwqnfZKsAae75RMP6jA</td>\n      <td>Roast Coffeehouse and Wine Bar</td>\n      <td>10359 104 Street NW</td>\n      <td>Edmonton</td>\n      <td>AB</td>\n      <td>T5J 1B9</td>\n      <td>53.546045</td>\n      <td>-113.499169</td>\n      <td>4.0</td>\n      <td>40</td>\n      <td>...</td>\n      <td>Coffee &amp; Tea, Food, Cafes, Bars, Wine Bars, Re...</td>\n      <td>b'{\"Monday\": \"8:0-18:0\", \"Tuesday\": \"8:0-18:0\"...</td>\n      <td>pLnTjS90gUlsq2tAjI9prA</td>\n      <td>G3h8pIclwUbuu3itJqF7ug</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0</td>\n      <td>4</td>\n      <td>With a Toast to Roast, I say welcome to the E-...</td>\n      <td>2012-09-11 23:54:24</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 22 columns</p>\n</div>"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the reviews\n",
    "positive = df[df['stars_y'] > 3]\n",
    "negative = df[df['stars_y'] <= 3]\n",
    "positive"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "# tokenizes positive and negative reviews\n",
    "pos_tokens = positive.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "\n",
    "neg_tokens = negative.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "1    [I, 'm, not, a, coffee, connoisseur, so, I, 'm...\n2    [I, really, loved, it, here, ,, makes, me, wis...\n4    [With, a, Toast, to, Roast, ,, I, say, welcome...\ndtype: object"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tokens[0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "pos_tags = pos_tokens.apply(pos_tag)\n",
    "neg_tags = neg_tokens.apply(pos_tag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "1    [(I, PRP), ('m, VBP), (not, RB), (a, DT), (cof...\n2    [(I, PRP), (really, RB), (loved, VBD), (it, PR...\n4    [(With, IN), (a, DT), (Toast, NNP), (to, TO), ...\ndtype: object"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags[0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lemmatization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "def lemmatize_sentence(tags):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in tags:\n",
    "        if tag.startswith('NN'):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n",
    "    return lemmatized_sentence\n",
    "\n",
    "pos_lemma = pos_tags.apply(lemmatize_sentence)\n",
    "neg_lemma = neg_tags.apply(lemmatize_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "1    [I, 'm, not, a, coffee, connoisseur, so, I, 'm...\n2    [I, really, love, it, here, ,, make, me, wish,...\n4    [With, a, Toast, to, Roast, ,, I, say, welcome...\ndtype: object"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_lemma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Noise Filtering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "#tba -> needs text investigation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# todo\n",
    "- word density analysis (maybe in EDA)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating Datasets\n",
    "\n",
    "- for Naive Bayes\n",
    "- Other Models require a bit more research"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "def get_reviews_for_model(tokens_list):\n",
    "    for review_token in tokens_list:\n",
    "        yield dict([token, True] for token in review_token)\n",
    "\n",
    "pos_token_for_model = get_reviews_for_model(pos_lemma)\n",
    "neg_token_for_model = get_reviews_for_model(neg_lemma)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "pos_df = [(review_dict, \"Positive\") for review_dict in pos_token_for_model]\n",
    "neg_df = [(review_dict, \"Positive\") for review_dict in neg_token_for_model]\n",
    "\n",
    "model_df = pos_df + neg_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "#train test split - move to modeling\n",
    "\n",
    "train_data = model_df[:3]\n",
    "test_data = model_df[3:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "#todo: find out how to save the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Naive Bayes Model\n",
    "- Move to modeling notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_data)\n",
    "print('Accuracy is: ', classify.accuracy(classifier, test_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "'Positive'"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample prediction\n",
    "classifier.classify(test_data[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}